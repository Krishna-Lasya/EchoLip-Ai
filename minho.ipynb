{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199368f5",
   "metadata": {},
   "source": [
    "# Wav2Lip Setup Guide - Mini(1.0) Environment\n",
    "\n",
    "## Step 1: Create Conda Environment\n",
    "\n",
    "```bash\n",
    "# Create conda environment with Python 3.6\n",
    "conda create -n \"Mini(1.0)\" python=3.6 -y\n",
    "\n",
    "# Activate the environment\n",
    "conda activate \"Mini(1.0)\"\n",
    "```\n",
    "\n",
    "## Step 2: Install Core Dependencies\n",
    "\n",
    "```bash\n",
    "# Install PyTorch (compatible with Python 3.6)\n",
    "conda install pytorch=1.7.1 torchvision=0.8.2 torchaudio=0.7.2 cpuonly -c pytorch\n",
    "\n",
    "# For GPU support (if available)\n",
    "# conda install pytorch=1.7.1 torchvision=0.8.2 torchaudio=0.7.2 cudatoolkit=10.2 -c pytorch\n",
    "\n",
    "# Install OpenCV\n",
    "pip install opencv-python==4.5.5.64\n",
    "\n",
    "# Install other required packages\n",
    "pip install numpy==1.19.5\n",
    "pip install scipy==1.5.4\n",
    "pip install scikit-image==0.17.2\n",
    "pip install pillow==8.4.0\n",
    "pip install librosa==0.8.1\n",
    "pip install matplotlib==3.3.4\n",
    "pip install tqdm==4.64.1\n",
    "pip install numba==0.53.1\n",
    "```\n",
    "\n",
    "## Step 3: Additional Dependencies\n",
    "\n",
    "```bash\n",
    "# Install face detection and alignment\n",
    "pip install dlib==19.22.1\n",
    "pip install face-recognition==1.3.0\n",
    "\n",
    "# Install audio processing\n",
    "pip install soundfile==0.10.3\n",
    "pip install resampy==0.2.2\n",
    "\n",
    "# Install video processing\n",
    "pip install imageio==2.9.0\n",
    "pip install imageio-ffmpeg==0.4.7\n",
    "```\n",
    "\n",
    "## Step 4: Download Pre-trained Models\n",
    "\n",
    "```bash\n",
    "# Create models directory\n",
    "mkdir -p models\n",
    "\n",
    "# Download Wav2Lip model (you'll need to download this manually)\n",
    "# wget -O models/wav2lip_gan.pth \"https://iiitaphyd-my.sharepoint.com/personal/radrabha_m_research_iiit_ac_in/_layouts/15/download.aspx?share=EdjI7bZlgApMqsVoEUUXpLsBxqXbn5z8VTmoxp2pgHDc\"\n",
    "\n",
    "# Download face detection model\n",
    "wget -O models/s3fd.pth \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\"\n",
    "```\n",
    "\n",
    "## Step 5: Verify Installation\n",
    "\n",
    "```bash\n",
    "# Test imports\n",
    "python -c \"import torch; print('PyTorch:', torch.__version__)\"\n",
    "python -c \"import cv2; print('OpenCV:', cv2.__version__)\"\n",
    "python -c \"import numpy; print('NumPy:', numpy.__version__)\"\n",
    "python -c \"import librosa; print('Librosa:', librosa.__version__)\"\n",
    "```\n",
    "\n",
    "## Important Notes\n",
    "\n",
    "1. **Python 3.6 Compatibility**: Some newer packages might not be available for Python 3.6. The versions specified above are tested to work together.\n",
    "\n",
    "2. **Model Downloads**: You'll need to manually download the Wav2Lip GAN model from the official repository due to licensing.\n",
    "\n",
    "3. **GPU Support**: If you have a compatible GPU, replace the CPU-only PyTorch installation with the CUDA version.\n",
    "\n",
    "4. **Face Detection**: The S3FD model is used for robust face detection in videos.\n",
    "\n",
    "## Environment Management\n",
    "\n",
    "```bash\n",
    "# List all conda environments\n",
    "conda env list\n",
    "\n",
    "# Activate the environment\n",
    "conda activate \"Mini(1.0)\"\n",
    "\n",
    "# Deactivate when done\n",
    "conda deactivate\n",
    "\n",
    "# Remove environment (if needed)\n",
    "conda env remove -n \"Mini(1.0)\"\n",
    "```\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "After setting up the environment, you can proceed with:\n",
    "1. Implementing the Wav2Lip inference code\n",
    "2. Setting up preprocessing utilities\n",
    "3. Creating the main sync application\n",
    "\n",
    "The environment \"Mini(1.0)\" is now ready for Wav2Lip development!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56df7d43",
   "metadata": {},
   "source": [
    " Download and install CMake from the official website\n",
    "##### https://cmake.org/download/\n",
    "###### OR install via conda\n",
    "conda install -c anaconda cmake\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df863d",
   "metadata": {},
   "source": [
    "# Errors\n",
    "dlib  pip install dlib==19.8.1\n",
    "# Alternative OpenCV installation\n",
    "conda install -c conda-forge opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eedd28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.5.5\n",
      "Face cascade loaded: False\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "\n",
    "# Test face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "print(\"Face cascade loaded:\", face_cascade.empty() == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "053acf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading OpenCV face detection model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "models/opencv_face_detector_uint8.pb: 278kiB [00:00, 4.17MiB/s]\n",
      "models/opencv_face_detector.pbtxt: 34.2kiB [00:00, 7.07MiB/s]                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models downloaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(url, filename):\n",
    "    \"\"\"Download file with progress bar\"\"\"\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    \n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    \n",
    "    with open(filename, 'wb') as file, tqdm(\n",
    "        desc=filename,\n",
    "        total=total_size,\n",
    "        unit='iB',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as pbar:\n",
    "        for data in response.iter_content(chunk_size=1024):\n",
    "            size = file.write(data)\n",
    "            pbar.update(size)\n",
    "\n",
    "# Download OpenCV face detection model (smaller alternative)\n",
    "print(\"Downloading OpenCV face detection model...\")\n",
    "download_file(\n",
    "    \"https://github.com/opencv/opencv/raw/4.x/samples/dnn/face_detector/opencv_face_detector_uint8.pb\",\n",
    "    \"models/opencv_face_detector_uint8.pb\"\n",
    ")\n",
    "\n",
    "download_file(\n",
    "    \"https://github.com/opencv/opencv/raw/4.x/samples/dnn/face_detector/opencv_face_detector.pbtxt\",\n",
    "    \"models/opencv_face_detector.pbtxt\"\n",
    ")\n",
    "\n",
    "print(\"Models downloaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3938a563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Face Detection Test ===\n",
      "❌ Haar Cascade face detection failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import subprocess\n",
    "\n",
    "def test_face_detection():\n",
    "    \"\"\"Test face detection\"\"\"\n",
    "    print(\"=== Face Detection Test ===\")\n",
    "    \n",
    "    # Test Haar Cascade\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    if not face_cascade.empty():\n",
    "        print(\"✅ Haar Cascade face detection is working\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"❌ Haar Cascade face detection failed\")\n",
    "        return False\n",
    "\n",
    "# Simple Wav2Lip implementation\n",
    "def run_wav2lip(face_video, audio_file, model_type=\"gan\"):\n",
    "    \"\"\"Run Wav2Lip on a video and audio file\"\"\"\n",
    "    # Setup paths\n",
    "    external_checkpoint_dir = \"E:\\\\checkpoints\"\n",
    "    input_video_dir = \"input_videos\"\n",
    "    input_audio_dir = \"input_audios\"\n",
    "    results_dir = \"results\"\n",
    "    \n",
    "    # Available models\n",
    "    models = {\n",
    "        \"gan\": \"Wav2Lip-SD-GAN.pt\",\n",
    "        \"nogan\": \"Wav2Lip-SD-NOGAN.pt\"\n",
    "    }\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(input_video_dir, exist_ok=True)\n",
    "    os.makedirs(input_audio_dir, exist_ok=True)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Get model path\n",
    "    model_path = os.path.join(external_checkpoint_dir, models.get(model_type.lower(), \"Wav2Lip-SD-GAN.pt\"))\n",
    "    \n",
    "    # Set file paths\n",
    "    video_path = os.path.join(input_video_dir, face_video)\n",
    "    audio_path = os.path.join(input_audio_dir, audio_file)\n",
    "    output_name = f\"{os.path.splitext(face_video)[0]}_{os.path.splitext(audio_file)[0]}.mp4\"\n",
    "    output_path = os.path.join(results_dir, output_name)\n",
    "    \n",
    "    # Run Wav2Lip\n",
    "    cmd = f\"python Wav2Lip/inference.py --checkpoint_path {model_path} --face {video_path} --audio {audio_path} --outfile {output_path}\"\n",
    "    print(f\"Running: {cmd}\")\n",
    "    subprocess.run(cmd, shell=True)\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"✅ Output saved to {output_path}\")\n",
    "        return output_path\n",
    "    else:\n",
    "        print(f\"❌ Failed to generate output\")\n",
    "        return None\n",
    "\n",
    "# Test face detection\n",
    "test_face_detection()\n",
    "\n",
    "# Example usage\n",
    "# run_wav2lip(\"input.mp4\", \"audio.wav\", \"gan\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a679df5",
   "metadata": {},
   "source": [
    "#### Clone the official repository\n",
    "git clone https://github.com/Rudrabha/Wav2Lip.git\n",
    "cd Wav2Lip\n",
    "\n",
    "#### Place it in: models/wav2lip_gan.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88fda3c",
   "metadata": {},
   "source": [
    "#### Clone the official repository\n",
    "git clone https://github.com/Rudrabha/Wav2Lip.git\n",
    "cd Wav2Lip\n",
    "\n",
    "#### Place it in: models/wav2lip_gan.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb88f88",
   "metadata": {},
   "source": [
    "#### Clone the official repository\n",
    "git clone https://github.com/Rudrabha/Wav2Lip.git\n",
    "cd Wav2Lip\n",
    "\n",
    "#### Place it in: models/wav2lip_gan.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b658d00",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ebbc1be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eefb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a0b4124",
   "metadata": {},
   "source": [
    "#### Clone the official repository\n",
    "git clone https://github.com/Rudrabha/Wav2Lip.git\n",
    "cd Wav2Lip\n",
    "\n",
    "#### Place it in: models/wav2lip_gan.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c2997",
   "metadata": {},
   "source": [
    "#### Clone the official repository\n",
    "git clone https://github.com/Rudrabha/Wav2Lip.git\n",
    "cd Wav2Lip\n",
    "\n",
    "#### Place it in: models/wav2lip_gan.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb68417e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46baf7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Face Detection Test ===\n",
      "✅ Haar Cascade face detection is working\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def test_face_detection():\n",
    "    \"\"\"Test face detection with proper path\"\"\"\n",
    "    print(\"=== Face Detection Test ===\")\n",
    "    \n",
    "    # Try to load Haar Cascade from standard location\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # If that fails, try to load from models directory\n",
    "    if face_cascade.empty():\n",
    "        model_path = \"models/haarcascade_frontalface_default.xml\"\n",
    "        if os.path.exists(model_path):\n",
    "            face_cascade = cv2.CascadeClassifier(model_path)\n",
    "            \n",
    "    if not face_cascade.empty():\n",
    "        print(\"✅ Haar Cascade face detection is working\")\n",
    "        return face_cascade\n",
    "    else:\n",
    "        print(\"❌ Haar Cascade face detection failed\")\n",
    "        print(\"Downloading Haar Cascade model...\")\n",
    "        \n",
    "        # Create models directory if it doesn't exist\n",
    "        os.makedirs(\"models\", exist_ok=True)\n",
    "        \n",
    "        # Download Haar Cascade model\n",
    "        import urllib.request\n",
    "        url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\"\n",
    "        model_path = \"models/haarcascade_frontalface_default.xml\"\n",
    "        urllib.request.urlretrieve(url, model_path)\n",
    "        \n",
    "        # Try loading again\n",
    "        face_cascade = cv2.CascadeClassifier(model_path)\n",
    "        if not face_cascade.empty():\n",
    "            print(\"✅ Haar Cascade face detection is now working\")\n",
    "            return face_cascade\n",
    "        else:\n",
    "            print(\"❌ Still failed to load Haar Cascade\")\n",
    "            return None\n",
    "\n",
    "# Run Wav2Lip with face detection\n",
    "def run_wav2lip(face_video, audio_file, model_type=\"gan\"):\n",
    "    \"\"\"Run Wav2Lip on a video and audio file\"\"\"\n",
    "    # Setup paths\n",
    "    external_checkpoint_dir = \"E:\\\\checkpoints\"\n",
    "    input_video_dir = \"input_videos\"\n",
    "    input_audio_dir = \"input_audios\"\n",
    "    results_dir = \"results\"\n",
    "    \n",
    "    # Available models\n",
    "    models = {\n",
    "        \"gan\": \"Wav2Lip-SD-GAN.pt\",\n",
    "        \"nogan\": \"Wav2Lip-SD-NOGAN.pt\"\n",
    "    }\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(input_video_dir, exist_ok=True)\n",
    "    os.makedirs(input_audio_dir, exist_ok=True)\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Get model path\n",
    "    model_path = os.path.join(external_checkpoint_dir, models.get(model_type.lower(), \"Wav2Lip-SD-GAN.pt\"))\n",
    "    \n",
    "    # Set file paths\n",
    "    video_path = os.path.join(input_video_dir, face_video)\n",
    "    audio_path = os.path.join(input_audio_dir, audio_file)\n",
    "    output_name = f\"{os.path.splitext(face_video)[0]}_{os.path.splitext(audio_file)[0]}.mp4\"\n",
    "    output_path = os.path.join(results_dir, output_name)\n",
    "    \n",
    "    # Run Wav2Lip\n",
    "    cmd = f\"python Wav2Lip/inference.py --checkpoint_path {model_path} --face {video_path} --audio {audio_path} --outfile {output_path}\"\n",
    "    print(f\"Running: {cmd}\")\n",
    "    subprocess.run(cmd, shell=True)\n",
    "    \n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"✅ Output saved to {output_path}\")\n",
    "        return output_path\n",
    "    else:\n",
    "        print(f\"❌ Failed to generate output\")\n",
    "        return None\n",
    "\n",
    "# Test face detection\n",
    "face_detector = test_face_detection()\n",
    "\n",
    "# Example usage\n",
    "# run_wav2lip(\"input.mp4\", \"audio.wav\", \"gan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b39d0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Wav2Lip with custom checkpoint. This may take some time...\n",
      "Lip-synced video saved to E:\\MINI_0.1\\results\\final_telugu_video.mp4\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define paths\n",
    "input_face = r\"E:\\MINI_0.1\\results\\video_only.mp4\"\n",
    "input_audio = r\"E:\\MINI_0.1\\input_audios\\telugu_audio.wav\"\n",
    "output_video = r\"E:\\MINI_0.1\\results\\final_telugu_video.mp4\"\n",
    "checkpoint_path = r\"E:\\checkpoints\\Wav2Lip-SD-GAN.pt\"\n",
    "\n",
    "# Run Wav2Lip\n",
    "command = [\n",
    "    \"python\", \n",
    "    \"Wav2Lip/inference.py\",\n",
    "    \"--checkpoint_path\", checkpoint_path,\n",
    "    \"--face\", input_face,\n",
    "    \"--audio\", input_audio,\n",
    "    \"--outfile\", output_video,\n",
    "    \"--pads\", \"0\", \"0\", \"0\", \"0\",\n",
    "    \"--nosmooth\"\n",
    "]\n",
    "\n",
    "print(\"Running Wav2Lip with custom checkpoint. This may take some time...\")\n",
    "subprocess.run(command)\n",
    "print(f\"Lip-synced video saved to {output_video}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2795be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]\n",
      "NumPy version: 1.19.5\n",
      "OpenCV not installed or DLL error. Installing via conda...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2fc3e9a5303f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"OpenCV version: {cv2.__version__}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2fc3e9a5303f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"OpenCV not installed or DLL error. Installing via conda...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"conda\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"install\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-c\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"conda-forge\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"opencv=4.5.5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\visualpath\\miniconda3\\envs\\Mini(1.0)\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[0mcheck_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-l\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m     \"\"\"\n\u001b[1;32m--> 306\u001b[1;33m     \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"args\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\visualpath\\miniconda3\\envs\\Mini(1.0)\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    285\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-l\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \"\"\"\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\visualpath\\miniconda3\\envs\\Mini(1.0)\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    727\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 729\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    730\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m             \u001b[1;31m# Cleanup if the child failed starting.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\visualpath\\miniconda3\\envs\\Mini(1.0)\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1015\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m                 \u001b[1;31m# Child is launched. Close the parent's copy of those pipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "# test_env.py\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "try:\n",
    "    import numpy\n",
    "    print(f\"NumPy version: {numpy.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"NumPy not installed. Installing...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numpy==1.19.5\"])\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "    print(f\"OpenCV version: {cv2.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"OpenCV not installed or DLL error. Installing via conda...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"conda\", \"install\", \"-c\", \"conda-forge\", \"opencv=4.5.5\", \"-y\"])\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "    print(f\"SciPy version: {scipy.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"SciPy not installed. Installing...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scipy==1.5.4\"])\n",
    "\n",
    "print(\"Environment check complete. If no errors above, you should be able to run Wav2Lip.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d07f508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First frame saved to E:\\MINI_0.1\\results\\first_frame.jpg\n",
      "Frame dimensions: 848x480\n",
      "Suggested face box: [120, 360, 304, 544]\n",
      "Please verify this box in the first frame image.\n",
      "If needed, adjust the box coordinates and run:\n",
      "python inference.py --checkpoint_path \"E:\\checkpoints\\Wav2Lip-SD-GAN.pt\" --face \"E:\\MINI_0.1\\results\\video_only.mp4\" --audio \"E:\\MINI_0.1\\input_audios\\telugu_audio.wav\" --outfile \"E:\\MINI_0.1\\results\\final_telugu_video.mp4\" --box 120 360 304 544 --nosmooth\n"
     ]
    }
   ],
   "source": [
    "# fix_face_detection.py\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "# Define paths\n",
    "input_video = r\"E:\\MINI_0.1\\results\\video_only.mp4\"\n",
    "input_audio = r\"E:\\MINI_0.1\\input_audios\\telugu_audio.wav\"\n",
    "output_video = r\"E:\\MINI_0.1\\results\\final_telugu_video.mp4\"\n",
    "checkpoint_path = r\"E:\\checkpoints\\Wav2Lip-SD-GAN.pt\"\n",
    "\n",
    "# Extract first frame to detect face manually\n",
    "def extract_first_frame():\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if ret:\n",
    "        # Save first frame\n",
    "        first_frame_path = r\"E:\\MINI_0.1\\results\\first_frame.jpg\"\n",
    "        cv2.imwrite(first_frame_path, frame)\n",
    "        print(f\"First frame saved to {first_frame_path}\")\n",
    "        \n",
    "        # Get frame dimensions\n",
    "        height, width = frame.shape[:2]\n",
    "        print(f\"Frame dimensions: {width}x{height}\")\n",
    "        \n",
    "        # Suggest a default face box (center of the frame)\n",
    "        center_x, center_y = width // 2, height // 2\n",
    "        box_size = min(width, height) // 2\n",
    "        \n",
    "        # Define box coordinates [y1, y2, x1, x2]\n",
    "        box = [\n",
    "            center_y - box_size//2,  # y1 (top)\n",
    "            center_y + box_size//2,  # y2 (bottom)\n",
    "            center_x - box_size//2,  # x1 (left)\n",
    "            center_x + box_size//2   # x2 (right)\n",
    "        ]\n",
    "        \n",
    "        return first_frame_path, box\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "# Run Wav2Lip with box parameter\n",
    "def run_wav2lip_with_box(box):\n",
    "    # Format box for command line\n",
    "    box_str = \" \".join(map(str, box))\n",
    "    \n",
    "    # Run Wav2Lip with box parameter\n",
    "    command = [\n",
    "        \"python\", \n",
    "        \"inference.py\",\n",
    "        \"--checkpoint_path\", checkpoint_path,\n",
    "        \"--face\", input_video,\n",
    "        \"--audio\", input_audio,\n",
    "        \"--outfile\", output_video,\n",
    "        \"--box\", *map(str, box),\n",
    "        \"--nosmooth\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Running Wav2Lip with manual face box...\")\n",
    "    print(\" \".join(command))\n",
    "    subprocess.run(command)\n",
    "\n",
    "# Main execution\n",
    "first_frame_path, suggested_box = extract_first_frame()\n",
    "if first_frame_path:\n",
    "    print(f\"Suggested face box: {suggested_box}\")\n",
    "    print(\"Please verify this box in the first frame image.\")\n",
    "    print(\"If needed, adjust the box coordinates and run:\")\n",
    "    print(f\"python inference.py --checkpoint_path \\\"{checkpoint_path}\\\" --face \\\"{input_video}\\\" --audio \\\"{input_audio}\\\" --outfile \\\"{output_video}\\\" --box {suggested_box[0]} {suggested_box[1]} {suggested_box[2]} {suggested_box[3]} --nosmooth\")\n",
    "    \n",
    "    # Uncomment to run automatically with suggested box\n",
    "    # run_wav2lip_with_box(suggested_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7ae25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame size: 848x480\n",
      "Using manual box: [120, 360, 212, 636]\n",
      "Running Wav2Lip with manual face box...\n",
      "python inference.py --checkpoint_path E:\\checkpoints\\Wav2Lip-SD-GAN.pt --face E:\\MINI_0.1\\results\\video_only.mp4 --audio E:\\MINI_0.1\\input_audios\\telugu_audio.wav --outfile E:\\MINI_0.1\\results\\final_telugu_video.mp4 --box 120 360 212 636 --wav2lip_batch_size 32 --nosmooth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'inference.py', '--checkpoint_path', 'E:\\\\checkpoints\\\\Wav2Lip-SD-GAN.pt', '--face', 'E:\\\\MINI_0.1\\\\results\\\\video_only.mp4', '--audio', 'E:\\\\MINI_0.1\\\\input_audios\\\\telugu_audio.wav', '--outfile', 'E:\\\\MINI_0.1\\\\results\\\\final_telugu_video.mp4', '--box', '120', '360', '212', '636', '--wav2lip_batch_size', '32', '--nosmooth'], returncode=2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple_wav2lip.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Define paths\n",
    "input_video = r\"E:\\MINI_0.1\\results\\video_only.mp4\"\n",
    "input_audio = r\"E:\\MINI_0.1\\input_audios\\telugu_audio.wav\"\n",
    "output_video = r\"E:\\MINI_0.1\\results\\final_telugu_video.mp4\"\n",
    "checkpoint_path = r\"E:\\checkpoints\\Wav2Lip-SD-GAN.pt\"\n",
    "\n",
    "# Create a simple manual box for the face\n",
    "def create_manual_box():\n",
    "    # Extract first frame\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if ret:\n",
    "        # Get frame dimensions\n",
    "        height, width = frame.shape[:2]\n",
    "        \n",
    "        # Create a box in the center of the frame (50% of frame size)\n",
    "        # Format: [y1, y2, x1, x2] - [top, bottom, left, right]\n",
    "        box = [\n",
    "            height//4,           # y1 (top)\n",
    "            height*3//4,         # y2 (bottom)\n",
    "            width//4,            # x1 (left)\n",
    "            width*3//4           # x2 (right)\n",
    "        ]\n",
    "        \n",
    "        print(f\"Frame size: {width}x{height}\")\n",
    "        print(f\"Using manual box: {box}\")\n",
    "        return box\n",
    "    else:\n",
    "        # Default box if video can't be read\n",
    "        return [0, 480, 0, 640]\n",
    "\n",
    "# Run Wav2Lip with manual box\n",
    "box = create_manual_box()\n",
    "\n",
    "# Create command with smaller batch size and manual box\n",
    "command = [\n",
    "    \"python\", \n",
    "    \"inference.py\",\n",
    "    \"--checkpoint_path\", checkpoint_path,\n",
    "    \"--face\", input_video,\n",
    "    \"--audio\", input_audio,\n",
    "    \"--outfile\", output_video,\n",
    "    \"--box\", str(box[0]), str(box[1]), str(box[2]), str(box[3]),\n",
    "    \"--wav2lip_batch_size\", \"32\",  # Smaller batch size to avoid memory issues\n",
    "    \"--nosmooth\"\n",
    "]\n",
    "\n",
    "print(\"Running Wav2Lip with manual face box...\")\n",
    "print(\" \".join(command))\n",
    "subprocess.run(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Wav2Lip with fixed script\n",
    "def run_fixed_wav2lip():\n",
    "    \"\"\"Run the fixed Wav2Lip implementation\"\"\"\n",
    "    input_video = r\"E:\\MINI_0.1\\results\\video_only.mp4\"\n",
    "    input_audio = r\"E:\\MINI_0.1\\input_audios\\telugu_audio.wav\"\n",
    "    output_video = r\"E:\\MINI_0.1\\results\\final_telugu_video.mp4\"\n",
    "    \n",
    "    # Run the batch file\n",
    "    subprocess.call([r\"E:\\MINI_0.1\\run_wav2lip_fixed.bat\"])\n",
    "    \n",
    "    # Check if output exists\n",
    "    if os.path.exists(output_video):\n",
    "        print(f\"✅ Wav2Lip successful! Output saved to: {output_video}\")\n",
    "        \n",
    "        # Get video info\n",
    "        cap = cv2.VideoCapture(output_video)\n",
    "        if cap.isOpened():\n",
    "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            duration = frame_count / fps\n",
    "            \n",
    "            print(f\"Video resolution: {width}x{height}\")\n",
    "            print(f\"FPS: {fps}\")\n",
    "            print(f\"Duration: {duration:.2f} seconds\")\n",
    "            print(f\"Total frames: {frame_count}\")\n",
    "            \n",
    "            cap.release()\n",
    "        return True\n",
    "    else:\n",
    "        print(\"❌ Wav2Lip failed. Check the error messages.\")\n",
    "        return False\n",
    "\n",
    "# Run the function\n",
    "run_fixed_wav2lip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "544f147d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PowerShell script created at E:\\MINI_0.1\\run_wav2lip.ps1\n",
      "Run it by right-clicking and selecting 'Run with PowerShell'\n"
     ]
    }
   ],
   "source": [
    "# Create a PowerShell script to run Wav2Lip\n",
    "with open(\"E:\\\\MINI_0.1\\\\run_wav2lip.ps1\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "# PowerShell script to run Wav2Lip\n",
    "Write-Host \"Running Wav2Lip with fixed script...\" -ForegroundColor Green\n",
    "\n",
    "# Change to Wav2Lip directory\n",
    "Set-Location -Path \"E:\\\\MINI_0.1\\\\wav2lip\"\n",
    "\n",
    "# Run the command\n",
    "python inference_fixed.py `\n",
    "--checkpoint_path \"E:\\\\checkpoints\\\\Wav2Lip-SD-GAN.pt\" `\n",
    "--face \"E:\\\\MINI_0.1\\\\results\\\\video_only.mp4\" `\n",
    "--audio \"E:\\\\MINI_0.1\\\\input_audios\\\\telugu_audio.wav\" `\n",
    "--outfile \"E:\\\\MINI_0.1\\\\results\\\\final_telugu_video.mp4\" `\n",
    "--box 120 360 212 636 `\n",
    "--wav2lip_batch_size 16 `\n",
    "--nosmooth\n",
    "\n",
    "# Check if successful\n",
    "if ($LASTEXITCODE -eq 0) {\n",
    "    Write-Host \"Success! Output saved to: E:\\\\MINI_0.1\\\\results\\\\final_telugu_video.mp4\" -ForegroundColor Green\n",
    "} else {\n",
    "    Write-Host \"Failed to generate output video. Check errors above.\" -ForegroundColor Red\n",
    "}\n",
    "\n",
    "Write-Host \"Press any key to continue...\"\n",
    "$null = $Host.UI.RawUI.ReadKey(\"NoEcho,IncludeKeyDown\")\n",
    "\"\"\")\n",
    "\n",
    "print(\"PowerShell script created at E:\\\\MINI_0.1\\\\run_wav2lip.ps1\")\n",
    "print(\"Run it by right-clicking and selecting 'Run with PowerShell'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c8ffe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMD script created at E:\\MINI_0.1\\run_wav2lip.cmd\n",
      "Run it by double-clicking the file in Windows Explorer\n"
     ]
    }
   ],
   "source": [
    "# Create a CMD script to run Wav2Lip\n",
    "with open(\"E:\\\\MINI_0.1\\\\run_wav2lip.cmd\", \"w\") as f:\n",
    "    f.write(\"\"\"@echo off\n",
    "echo Running Wav2Lip with fixed script...\n",
    "\n",
    "cd /d E:\\\\MINI_0.1\\\\wav2lip\n",
    "\n",
    "python inference_fixed.py ^\n",
    "--checkpoint_path \"E:\\\\checkpoints\\\\Wav2Lip-SD-GAN.pt\" ^\n",
    "--face \"E:\\\\MINI_0.1\\\\results\\\\video_only.mp4\" ^\n",
    "--audio \"E:\\\\MINI_0.1\\\\input_audios\\\\telugu_audio.wav\" ^\n",
    "--outfile \"E:\\\\MINI_0.1\\\\results\\\\final_telugu_video.mp4\" ^\n",
    "--box 120 360 212 636 ^\n",
    "--wav2lip_batch_size 16 ^\n",
    "--nosmooth\n",
    "\n",
    "if %ERRORLEVEL% EQU 0 (\n",
    "    echo Success! Output saved to: E:\\\\MINI_0.1\\\\results\\\\final_telugu_video.mp4\n",
    ") else (\n",
    "    echo Failed to generate output video. Check errors above.\n",
    ")\n",
    "\n",
    "pause\n",
    "\"\"\")\n",
    "\n",
    "print(\"CMD script created at E:\\\\MINI_0.1\\\\run_wav2lip.cmd\")\n",
    "print(\"Run it by double-clicking the file in Windows Explorer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55627f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mini(1.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
