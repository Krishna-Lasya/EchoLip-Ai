{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2b23cc9",
   "metadata": {},
   "source": [
    "git clone https://github.com/Rudrabha/Wav2Lip.git\n",
    "cd Wav2Lip\n",
    "\n",
    "pip install dataclasses\n",
    "pip install opencv-contrib-python==4.5.5.64\n",
    "pip install torch==1.7.1+cpu torchvision==0.8.2+cpu torchaudio==0.7.2 -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "pip install -r requirements.txt --no-deps\n",
    "pip list :\n",
    "     (echolip) PS E:\\MINI_0.1\\Wav2Lip> pip list\n",
    "Package               Version\n",
    "--------------------- ---------\n",
    "certifi               2021.5.30\n",
    "dataclasses           0.8\n",
    "numpy                 1.19.5\n",
    "opencv-contrib-python 4.5.5.64\n",
    "Pillow                8.4.0\n",
    "pip                   21.2.2\n",
    "setuptools            58.0.4\n",
    "torch                 1.7.1+cpu\n",
    "torchaudio            0.7.2\n",
    "torchvision           0.8.2+cpu\n",
    "typing_extensions     4.1.1\n",
    "wheel                 0.37.1\n",
    "wincertstore          0.2\n",
    "(echolip) PS E:\\MINI_0.1\\Wav2Lip> \n",
    "> pip install face-detection==0.2.1\n",
    "\n",
    "conda install -c conda-forge ffmpeg\n",
    "\"E:\\MINI_0.1\\Wav2Lip\\face_detection\\detection\\sfd\\s3fd.pth\"(Install this from goofle or kgle and rename the path)\n",
    "pip install tqdm==4.45.0 numba==0.48\n",
    "librosa==0.7.0\n",
    "\n",
    "comment for training :\n",
    "(echolip) PS E:\\MINI_0.1\\Wav2Lip> python preprocess.py --data_root E:\\MINI_0.1\\input_videos_mp4_only --preprocessed_root E:\\MINI_0.1\\preprocessed_data --ngpu 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2abd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if sys.version_info[0] < 3 and sys.version_info[1] < 2:\n",
    "    raise Exception(\"Must be using >= Python 3.2\")\n",
    "\n",
    "from os import listdir, path\n",
    "\n",
    "if not path.isfile('face_detection/detection/sfd/s3fd.pth'):\n",
    "    raise FileNotFoundError('Save the s3fd model to face_detection/detection/sfd/s3fd.pth \\\n",
    "                            before running this script!')\n",
    "\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "import argparse, os, cv2, traceback, subprocess\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import audio\n",
    "from hparams import hparams as hp\n",
    "import torch  # added to check CUDA availability\n",
    "\n",
    "import face_detection\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--ngpu', help='Number of GPUs across which to run in parallel', default=1, type=int)\n",
    "parser.add_argument('--batch_size', help='Single GPU Face detection batch size', default=32, type=int)\n",
    "parser.add_argument(\"--data_root\", help=\"Root folder of the LRS2 dataset\", required=True)\n",
    "parser.add_argument(\"--preprocessed_root\", help=\"Root folder of the preprocessed dataset\", required=True)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "# SAFER: check for CUDA availability\n",
    "if args.ngpu > 0 and not torch.cuda.is_available():\n",
    "    print(\" Warning: CUDA not available! Falling back to CPU.\")\n",
    "    args.ngpu = 0\n",
    "\n",
    "# Device list preparation\n",
    "device_list = ['cuda:{}'.format(i) for i in range(args.ngpu)] if args.ngpu > 0 else ['cpu']\n",
    "\n",
    "# Initialize FaceAlignment for each device\n",
    "fa = [face_detection.FaceAlignment(face_detection.LandmarksType._2D, flip_input=False, device=device) for device in device_list]\n",
    "\n",
    "# FFMPEG command template\n",
    "template = 'ffmpeg -loglevel panic -y -i \"{}\" -strict -2 \"{}\"'\n",
    "\n",
    "# Function to process video frames\n",
    "def process_video_file(vfile, args, gpu_id):\n",
    "    video_stream = cv2.VideoCapture(vfile)\n",
    "\n",
    "    frames = []\n",
    "    while 1:\n",
    "        still_reading, frame = video_stream.read()\n",
    "        if not still_reading:\n",
    "            video_stream.release()\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "    vidname = os.path.basename(vfile).split('.')[0]\n",
    "    dirname = os.path.basename(os.path.dirname(vfile))  # safer path extraction\n",
    "\n",
    "    fulldir = path.join(args.preprocessed_root, dirname, vidname)\n",
    "    os.makedirs(fulldir, exist_ok=True)\n",
    "\n",
    "    batches = [frames[i:i + args.batch_size] for i in range(0, len(frames), args.batch_size)]\n",
    "\n",
    "    i = -1\n",
    "    for fb in batches:\n",
    "        preds = fa[gpu_id].get_detections_for_batch(np.asarray(fb))\n",
    "\n",
    "        for j, f in enumerate(preds):\n",
    "            i += 1\n",
    "            if f is None:\n",
    "                continue\n",
    "\n",
    "            x1, y1, x2, y2 = f\n",
    "            cv2.imwrite(path.join(fulldir, '{}.jpg'.format(i)), fb[j][y1:y2, x1:x2])\n",
    "\n",
    "# Function to process audio extraction\n",
    "def process_audio_file(vfile, args):\n",
    "    vidname = os.path.basename(vfile).split('.')[0]\n",
    "    dirname = os.path.basename(os.path.dirname(vfile))\n",
    "\n",
    "    fulldir = path.join(args.preprocessed_root, dirname, vidname)\n",
    "    os.makedirs(fulldir, exist_ok=True)\n",
    "\n",
    "    wavpath = path.join(fulldir, 'audio.wav')\n",
    "\n",
    "    command = template.format(vfile, wavpath)\n",
    "    subprocess.call(command, shell=True)\n",
    "\n",
    "# Multiprocessing handler\n",
    "def mp_handler(job):\n",
    "    vfile, args, gpu_id = job\n",
    "    try:\n",
    "        process_video_file(vfile, args, gpu_id)\n",
    "    except KeyboardInterrupt:\n",
    "        exit(0)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "\n",
    "# MAIN FUNCTION\n",
    "def main(args):\n",
    "    print('Started processing for {} with {} GPU(s)'.format(args.data_root, args.ngpu))\n",
    "\n",
    "    # Match both \"*/video.mp4\" and also \"video.mp4\" if flat folder (your case)\n",
    "    filelist = glob(path.join(args.data_root, '*.mp4')) + glob(path.join(args.data_root, '*/*.mp4'))\n",
    "\n",
    "    if len(filelist) == 0:\n",
    "        print(\" No MP4 files found in {}\".format(args.data_root))\n",
    "        return\n",
    "\n",
    "    gpu_count = args.ngpu if args.ngpu > 0 else 1\n",
    "    jobs = [(vfile, args, i % gpu_count) for i, vfile in enumerate(filelist)]\n",
    "\n",
    "    print(\"Processing {} video files...\".format(len(filelist)))\n",
    "\n",
    "    p = ThreadPoolExecutor(max(1, args.ngpu))\n",
    "\n",
    "    futures = [p.submit(mp_handler, j) for j in jobs]\n",
    "    _ = [r.result() for r in tqdm(as_completed(futures), total=len(futures))]\n",
    "\n",
    "    print('Dumping audios...')\n",
    "\n",
    "    for vfile in tqdm(filelist):\n",
    "        try:\n",
    "            process_audio_file(vfile, args)\n",
    "        except KeyboardInterrupt:\n",
    "            exit(0)\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "# Entry point\n",
    "if __name__ == '__main__':\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde34c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidia-smi\n",
    "\n",
    "conda activate echolip\n",
    "\n",
    "pip install torch==2.2.0+cu122 torchvision==0.17.0+cu122 torchaudio==2.2.0+cu122 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "pip install -U tqdm\n",
    "\n",
    "python preprocess.py --ngpu 4\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echolip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
